{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from classifier import *\n",
    "import features as fe \n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_face_img, X_train_nonface_img, X_test_img, y_train_face, y_train_nonface, y_test = ut.get_test_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = np.concatenate((X_train_face_img, X_train_nonface_img))\n",
    "y_train = np.concatenate((y_train_face, y_train_nonface))\n",
    "X_train_ada, y_train_ada = ut.random_subset(X_train_img, y_train, 100)\n",
    "X_test_ada, y_test_ada = ut.random_subset(X_test_img, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = fe.get_rectanges(19, 19)\n",
    "no_rect = fe.get_no_rectangles(19, 19)\n",
    "X_train_ada_fe = fe.par_feature_extraction_images(X_train_ada, rect, no_rect)\n",
    "X_test_ada_fe = fe.par_feature_extraction_images(X_test_ada, rect, no_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = AdaBoostClassifier()\n",
    "a.fit(X_train_ada_fe, y_train_ada, 2)\n",
    "accuracy = a.score(X_test_ada_fe, y_test_ada)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = list(range(1, 10))\n",
    "accuracies = []\n",
    "a = AdaBoostClassifier()\n",
    "for iter in iters:\n",
    "    a.fit(X_train_ada_fe, y_train_ada, iter)\n",
    "    accuracy = a.score(X_test_ada_fe, y_test_ada)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"accuraties\")\n",
    "plt.plot(iters, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.threshold*0.98)\n",
    "print(a.false_positive_rate(X_test_ada_fe, y_test_ada))\n",
    "print(a.detection_rate(X_test_ada_fe, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into 10 folds\n",
    "X_train_folds = np.array_split(X_train_ada_fe, 10)\n",
    "y_train_folds = np.array_split(y_train_ada, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.9\n",
    "d = 0.9\n",
    "F_target = 0.001\n",
    "Threshold_retention = 0.99\n",
    "Strong_Classifiers = []\n",
    "\n",
    "def Cascade_Classifier(X_test,y_test, Strong_Classifiers):\n",
    "    y_pred = np.zeros(len(X_test))\n",
    "    no_of_negatives = np.sum(y_test == 0)\n",
    "    total_test_y = len(y_test)\n",
    "    for i in range(len(Strong_Classifiers)):\n",
    "        print(y_pred.shape, X_test.shape,y_test.shape)\n",
    "        y_pred = Strong_Classifiers[i].predict(X_test)\n",
    "        X_test = X_test[y_pred == 1]\n",
    "        y_test = y_test[y_pred == 1]\n",
    "        y_pred = y_pred[y_pred == 1]\n",
    "        if len(X_test) == 0:\n",
    "            break\n",
    "    false_positive_rate = np.sum((y_pred == 1) & (y_test == 0))/no_of_negatives\n",
    "    detection_rate = np.sum((y_pred == 1)& (y_test == 1))/total_test_y\n",
    "    return y_pred, false_positive_rate, detection_rate\n",
    "\n",
    "\n",
    "def get_avg_fpr_dtr(Strong_Classifiers,a,X_train_folds, y_train_folds, no_of_folds,no_of_features):\n",
    "    false_positive_rate = 0\n",
    "    detection_rate = 0\n",
    "    indices = np.random.choice(10, no_of_folds, replace=False)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in indices:\n",
    "        X_test.append(X_train_folds[i])\n",
    "        y_test.append(y_train_folds[i])\n",
    "\n",
    "    X_test = np.concatenate(X_test)\n",
    "    y_test = np.concatenate(y_test)\n",
    "    X_train = np.concatenate([X_train_folds[i] for i in range(10) if i not in indices])\n",
    "    y_train = np.concatenate([y_train_folds[i] for i in range(10) if i not in indices])\n",
    "    print(\"shapes before: \" ,X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    for i in range(len(Strong_Classifiers)):\n",
    "        y_pred = Strong_Classifiers[i].predict(X_train)\n",
    "        X_train = X_train[y_pred == 1]\n",
    "        y_train = y_train[y_pred == 1]\n",
    "        if len(X_train) == 0:\n",
    "            break\n",
    "    # fit a new classifier on the remaining data\n",
    "    print(\"shapes after: \" ,X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    a.fit(X_train, y_train, no_of_features)\n",
    "    # add the classifier to the list of strong classifiers\n",
    "    Strong_Classifiers.append(a)    \n",
    "    pred_values,false_positive_rate, detection_rate = Cascade_Classifier(X_test,y_test, Strong_Classifiers)\n",
    "    return false_positive_rate, detection_rate, Strong_Classifiers[-1], X_test, y_test,Strong_Classifiers\n",
    "\n",
    "def Train_Cascade(f,d,F_target,Threshold_retention):    \n",
    "    F = [0.6]\n",
    "    D = [0.6]\n",
    "    F_new = F[-1]\n",
    "    First_Strong_Classifier = AdaBoostClassifier()    \n",
    "    Strong_Classifiers = []\n",
    "    while F_new > F_target:\n",
    "        a = AdaBoostClassifier()\n",
    "        F_new = F[-1]\n",
    "        no_of_features = 0        \n",
    "        while F_new > f*F[-1]:\n",
    "            no_of_features += 1       \n",
    "            fpr, dtr, a,X_test_returned,y_test_returned,Strong_Classifiers = get_avg_fpr_dtr(Strong_Classifiers,a,X_train_folds, y_train_folds, 3,no_of_features)\n",
    "            F_new = fpr\n",
    "            D_new = dtr\n",
    "            print(\"passed the first while loop\")\n",
    "            # decrease the threshold for the ith strong classifier in the cascade\n",
    "            while(True):            \n",
    "                Strong_Classifiers[-1].threshold = Strong_Classifiers[-1].threshold*Threshold_retention\n",
    "                print(Strong_Classifiers[-1].threshold)\n",
    "                a = Strong_Classifiers[-1]\n",
    "                print(a.threshold)\n",
    "                y_preds,fpr,dtr = Cascade_Classifier(X_test_returned,y_test_returned, Strong_Classifiers)\n",
    "                F_new = fpr\n",
    "                D_new = dtr\n",
    "                print(\"in the second while loop and the threshold is\", a.threshold,\" \", F_new, \" \", D_new,\" \",d*D[-1],\" \",no_of_features)\n",
    "                if D_new > d*D[-1]:          \n",
    "                    break      \n",
    "            # remove the last strong classifier from the cascade\n",
    "            Strong_Classifiers.pop()\n",
    "\n",
    "\n",
    "        print(F_new)          \n",
    "        F.append(F_new)\n",
    "        D.append(D_new)\n",
    "        Strong_Classifiers.append(a)     \n",
    "    return Strong_Classifiers\n",
    "\n",
    "Strong_Classifiers = np.array(Train_Cascade(f,d,F_target,Threshold_retention))\n",
    "print(\"the length of the strong classifiers is\", len(Strong_Classifiers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, false_positive_rate, detection_rate = Cascade_Classifier(X_test_ada_fe,y_test_ada, Strong_Classifiers)\n",
    "print(\"the accuracy of the cascade classifier is\", np.sum(y_pred == y_test_ada)/len(y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
