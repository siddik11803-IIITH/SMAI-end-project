{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from classifier import *\n",
    "import features as fe \n",
    "import utils as ut\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_data(Dataset_Size):\n",
    "    rect = fe.get_rectanges(19, 19)\n",
    "    no_rect = fe.get_no_rectangles(19, 19)\n",
    "    X_train_face_img, X_train_nonface_img, X_test_img, y_train_face, y_train_nonface, y_test = ut.get_test_train_data()\n",
    "    X_train_sub_nonface_img, y_train_sub_nonface = ut.random_subset(X_train_nonface_img, y_train_nonface, len(X_train_face_img))\n",
    "    assert(len(X_train_face_img) == len(X_train_sub_nonface_img))\n",
    "    assert(len(y_train_face) == len(y_train_sub_nonface))\n",
    "    assert(len(X_train_face_img) == len(y_train_face))\n",
    "    assert(len(X_train_sub_nonface_img) == len(y_train_sub_nonface))\n",
    "\n",
    "    X_train_img = np.concatenate((X_train_face_img, X_train_sub_nonface_img))\n",
    "    y_train = np.concatenate((y_train_face, y_train_sub_nonface))\n",
    "\n",
    "    X_data, y_data = ut.random_subset(X_train_img, y_train, Dataset_Size)\n",
    "    X_data_fe = fe.par_feature_extraction_images(X_data, rect, no_rect)\n",
    "    return X_data_fe, y_data\n",
    "    \n",
    "\n",
    "def Split_Data(X_data, y_data):\n",
    "    return train_test_split(X_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Create_data(200)\n",
    "X_train, X_test, y_train, y_test = Split_Data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdaBoostClassifier()\n",
    "a.fit(X_train, y_train, 2)\n",
    "print(a.detection_rate(X_test, y_test))\n",
    "print(a.false_positive_rate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = list(range(1, 50))\n",
    "accuracies = []\n",
    "dectections = []\n",
    "false_possitives = []\n",
    "a = AdaBoostClassifier()\n",
    "for iter in iters:\n",
    "    a.fit(X_train, y_train, iter)\n",
    "    accuracy = a.score(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"accuraties\")\n",
    "plt.plot(iters, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cascade_Classifier_predict(X_test, y_test, Strong_Classifiers):\n",
    "    y_preds = []\n",
    "    for i in range((len(Strong_Classifiers))):\n",
    "        y_pred = Strong_Classifiers[i].predict(X_test)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    ans = np.zeros(len(y_test)) \n",
    "    for i in range(len(y_test)):\n",
    "        is_one = True\n",
    "        for j in range(len(Strong_Classifiers)):\n",
    "            if(y_preds[j][i] == 0):\n",
    "                is_one = False\n",
    "                break\n",
    "        if(is_one == True):\n",
    "            ans[i] = 1\n",
    "        else:\n",
    "            ans[i] = 0\n",
    "    return ans\n",
    "\n",
    "\n",
    "def Cascade_Classifier(X_test,y_test, Strong_Classifiers):\n",
    "    y_pred = Cascade_Classifier_predict(X_test, y_test, Strong_Classifiers)\n",
    "    false_positive_rate = np.sum((y_pred == 1) & (y_test == 0))/np.sum(y_test == 0)\n",
    "    detection_rate = np.sum((y_pred == 1)& (y_test == 1))/np.sum(y_test == 1)\n",
    "    return false_positive_rate, detection_rate\n",
    "\n",
    "\n",
    "\n",
    "def Create_validation_sets(X_all, y_all):\n",
    "    X_train, X_valid, y_train, y_valid = Split_Data(X_all, y_all)\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "\n",
    "def Train_Cascade(X_train_all, y_train_all):    \n",
    "    F = [0.6]\n",
    "    D = [0.9]\n",
    "    f = 0.999\n",
    "    d = 0.99\n",
    "    F_target = 0.07\n",
    "    Threshold_retention = 0.99\n",
    "    \n",
    "    F_new = F[-1]\n",
    "    Strong_Classifiers = []\n",
    "    no_outermost_loops = 0\n",
    "    X_train, X_valid, y_train, y_valid = Create_validation_sets(X_train_all, y_train_all)\n",
    "    while F_new > F_target and no_outermost_loops < 5:\n",
    "        no_outermost_loops += 1\n",
    "        a = AdaBoostClassifier()\n",
    "        F_new = F[-1]\n",
    "\n",
    "        no_of_features = 0        \n",
    "        while F_new > f*F[-1] and no_of_features < 50:          #### Hard coded\n",
    "            no_of_features += 1       \n",
    "            a.fit(X_train, y_train, no_of_features)\n",
    "            Strong_Classifiers.append(a)\n",
    "            F_new, D_new = Cascade_Classifier(X_valid, y_valid, Strong_Classifiers)\n",
    "\n",
    "            no_innermost_iter = 0\n",
    "            while(no_innermost_iter < 50):            #### Hard coded\n",
    "                no_innermost_iter += 1\n",
    "                a = Strong_Classifiers[-1]\n",
    "                Strong_Classifiers[-1].threshold = Strong_Classifiers[-1].threshold*Threshold_retention\n",
    "                F_new, D_new = Cascade_Classifier(X_valid, y_valid, Strong_Classifiers)\n",
    "                print(\"L1:\", len(Strong_Classifiers), \" L2:\", no_of_features, \" L3:\", no_innermost_iter, \" F_new: \", F_new, \" F_tar:  \", f*F[-1], \" D_new:\", D_new, \"D_expected:\",d*D[-1], \" Threshold:\" a.threshold)\n",
    "                if D_new > d*D[-1]:       #### Hard coded          \n",
    "                    break     \n",
    "                if a.threshold < 1e-10:   #### Hard coded\n",
    "                    break\n",
    "                \n",
    "            Strong_Classifiers.pop()\n",
    "\n",
    "        F.append(F_new)\n",
    "        D.append(D_new)\n",
    "        Strong_Classifiers.append(a)  \n",
    "        y_pred = a.predict(X_train)\n",
    "        X_train = X_train[y_pred == 1] \n",
    "        y_train = y_train[y_pred == 1]\n",
    "        if(len(y_train) < 10):\n",
    "            break\n",
    "    return Strong_Classifiers\n",
    "\n",
    "\n",
    "\n",
    "Strong_Classifiers = np.array(Train_Cascade(X_train, y_train))\n",
    "print(\"the length of the strong classifiers is\", len(Strong_Classifiers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Cascade_Classifier_predict(X_test, y_test, Strong_Classifiers)\n",
    "print(\"the accuracy of the cascade classifier is\", np.sum(y_pred == y_test)/len(y_test))\n",
    "print(\"the accuracy of the cascade detection is\", np.sum((y_pred == 1) &  (y_test == 1))/sum(y_test == 1))\n",
    "print(\"the accuracy of the cascade false postictive is\", np.sum((y_pred == 1) & (y_test == 0))/sum(y_test == 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a7d377a1274c570b9298af95c2593971340dd8baaff5322501e4bff77555216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
